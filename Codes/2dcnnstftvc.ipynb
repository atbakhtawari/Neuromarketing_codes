{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 108510672 into shape (11068,129,19,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m stft_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(stft_data)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Reshape the STFT data for CNN input (samples, height, width, channels)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m stft_data_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mstft_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstft_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstft_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstft_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Flatten the labels array\u001b[39;00m\n\u001b[0;32m     30\u001b[0m labels_flat \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 108510672 into shape (11068,129,19,1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.signal import stft\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\UC\\\\Documents\\\\NeuMa\\\\22117124\\\\new.mat'\n",
    "data = sio.loadmat(file_path)\n",
    "eeg_data = data['EEG']\n",
    "labels = data['label_list']\n",
    "\n",
    "# Reshape EEG data to have samples as the first dimension\n",
    "eeg_data_reshaped = np.transpose(eeg_data, (2, 1, 0))\n",
    "\n",
    "# Apply STFT to EEG data\n",
    "_, _, stft_data = stft(eeg_data_reshaped, axis=1)\n",
    "stft_data = np.abs(stft_data)\n",
    "\n",
    "# Reshape the STFT data for CNN input (samples, height, width, channels)\n",
    "stft_data_reshaped = stft_data.reshape(stft_data.shape[0], stft_data.shape[1], stft_data.shape[2], 1)\n",
    "\n",
    "# Flatten the labels array\n",
    "labels_flat = labels.flatten()\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "# Flatten the STFT data for SMOTE application\n",
    "stft_data_flattened = stft_data_reshaped.reshape(stft_data_reshaped.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "stft_data_resampled, labels_resampled = smote.fit_resample(stft_data_flattened, labels_flat)\n",
    "\n",
    "# Reshape back to the original shape for CNN input\n",
    "stft_data_resampled = stft_data_resampled.reshape(-1, stft_data.shape[1], stft_data.shape[2], 1)\n",
    "\n",
    "# Check the shape of resampled data and labels\n",
    "print(\"Shape of resampled data:\", stft_data_resampled.shape)\n",
    "print(\"Shape of resampled labels:\", labels_resampled.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stft_data_reshaped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstft_data_reshaped\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stft_data_reshaped' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the resampled data and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(stft_data_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shapes after splitting\n",
    "print(\"Shape of training data:\", X_train.shape)\n",
    "print(\"Shape of training labels:\", y_train.shape)\n",
    "print(\"Shape of test data:\", X_test.shape)\n",
    "print(\"Shape of test labels:\", y_test.shape)\n",
    "\n",
    "# Build the CNN model for feature extraction\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "cnn_model.add(MaxPooling2D((2, 2)))\n",
    "cnn_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D((2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Create a model to output the flattened features\n",
    "feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.output)\n",
    "\n",
    "# Extract features from training and test data\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n",
    "\n",
    "# Train ensemble classifier on the extracted features\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators=[('rf', rf_clf), ('svm', svm_clf)], voting='soft')\n",
    "ensemble_clf.fit(X_train_features, y_train)\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = ensemble_clf.predict(X_test_features)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, ensemble_clf.predict_proba(X_test_features)[:, 1])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, ensemble_clf.predict_proba(X_test_features)[:, 1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UC\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.signal import welch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, LSTM\n",
    "import optuna\n",
    "import pywt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the data\n",
    "file_path = 'C:\\\\Users\\\\UC\\\\Documents\\\\NeuMa\\\\22117124\\\\new.mat'\n",
    "new = sio.loadmat(file_path)\n",
    "Label = new['label_list'].flatten()\n",
    "EEG = new['EEG']\n",
    "ET = new['ET']\n",
    "\n",
    "# Feature extraction for ML (EEG)\n",
    "def extract_ml_features(data):\n",
    "    features = []\n",
    "    for i in range(data.shape[2]):  # Iterate over samples\n",
    "        sample = data[:, :, i]\n",
    "        sample_features = []\n",
    "        for j in range(data.shape[0]):  # Iterate over channels\n",
    "            channel_data = sample[j, :]\n",
    "            # Statistical features\n",
    "            mean = np.mean(channel_data)\n",
    "            var = np.var(channel_data)\n",
    "            skewness = skew(channel_data)\n",
    "            kurt = kurtosis(channel_data)\n",
    "            # Frequency domain features using Welch's method\n",
    "            freqs, psd = welch(channel_data)\n",
    "            psd_mean = np.mean(psd)\n",
    "            psd_std = np.std(psd)\n",
    "            # Combine all features\n",
    "            sample_features.extend([mean, var, skewness, kurt, psd_mean, psd_std])\n",
    "        features.append(sample_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Wavelet transform features (EEG)\n",
    "def extract_wavelet_features(data):\n",
    "    features = []\n",
    "    for i in range(data.shape[2]):  # Iterate over samples\n",
    "        sample = data[:, :, i]\n",
    "        sample_features = []\n",
    "        for j in range(data.shape[0]):  # Iterate over channels\n",
    "            channel_data = sample[j, :]\n",
    "            coeffs = pywt.wavedec(channel_data, 'db4', level=4)\n",
    "            for coeff in coeffs:\n",
    "                sample_features.extend([np.mean(coeff), np.std(coeff)])\n",
    "        features.append(sample_features)\n",
    "    return np.array(features)\n",
    "\n",
    "ml_features = extract_ml_features(EEG)\n",
    "wavelet_features = extract_wavelet_features(EEG)\n",
    "ml_features = np.concatenate((ml_features, wavelet_features), axis=1)\n",
    "\n",
    "# Feature extraction for DL (EEG) using CNN and LSTM\n",
    "input_shape = (EEG.shape[0], EEG.shape[1], 1)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "flatten = Flatten()(pool2)\n",
    "\n",
    "# Reshape for LSTM layer\n",
    "reshape_layer = Reshape((flatten.shape[1], 1))(flatten)\n",
    "lstm_layer = LSTM(64)(reshape_layer)\n",
    "dense1 = Dense(128, activation='relu')(lstm_layer)\n",
    "output_layer = Dense(64, activation='relu')(dense1)  # Output for feature extraction\n",
    "\n",
    "cnn_rnn_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "cnn_rnn_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape data for CNN input\n",
    "data_cnn = EEG.reshape(EEG.shape[2], EEG.shape[0], EEG.shape[1], 1)\n",
    "\n",
    "cnn_rnn_features = cnn_rnn_model.predict(data_cnn)\n",
    "\n",
    "# Combine ML and DL features (EEG)\n",
    "combined_eeg_features = np.concatenate((ml_features, cnn_rnn_features), axis=1)\n",
    "\n",
    "# Feature extraction (ET)\n",
    "image_list = []\n",
    "handcrafted_features = []\n",
    "\n",
    "for sample_idx in range(ET.shape[2]):\n",
    "    x_left, y_left, pupil_left, x_right, y_right, pupil_right = ET[:, :, sample_idx]\n",
    "    \n",
    "    gaze_plot = np.zeros((64, 64, 3), dtype=np.uint8)  # Initialize as black image\n",
    "\n",
    "    scaled_x_left = (x_left * 1920 / 30).astype(int)  # 1920 / 30 ~ 64\n",
    "    scaled_y_left = (y_left * 1080 / 16.875).astype(int)  # 1080 / 16.875 ~ 64\n",
    "    scaled_x_right = (x_right * 1920 / 30).astype(int)\n",
    "    scaled_y_right = (y_right * 1080 / 16.875).astype(int)\n",
    "\n",
    "    for i in range(120):\n",
    "        if 0 <= scaled_x_left[i] < 64 and 0 <= scaled_y_left[i] < 64:\n",
    "            gaze_plot[scaled_y_left[i], scaled_x_left[i]] = [255, 255, 255]  # White color\n",
    "        if 0 <= scaled_x_right[i] < 64 and 0 <= scaled_y_right[i] < 64:\n",
    "            gaze_plot[scaled_y_right[i], scaled_x_right[i]] = [255, 255, 255]  # White color\n",
    "\n",
    "    image_list.append(gaze_plot)\n",
    "\n",
    "    mean_left = np.mean([x_left, y_left, pupil_left])\n",
    "    std_left = np.std([x_left, y_left, pupil_left])\n",
    "    mean_right = np.mean([x_right, y_right, pupil_right])\n",
    "    std_right = np.std([x_right, y_right, pupil_right])\n",
    "    \n",
    "    handcrafted_features.append([mean_left, std_left, mean_right, std_right])\n",
    "\n",
    "image_array = np.array(image_list)\n",
    "handcrafted_features = np.array(handcrafted_features)\n",
    "\n",
    "# Reshape images to have a single channel (grayscale)\n",
    "image_array = np.expand_dims(image_array, axis=-1)\n",
    "image_array = image_array / 255.0  # Normalize the image data to the range [0, 1]\n",
    "\n",
    "# LeNet-5 for feature extraction (ET)\n",
    "lenet5 = tf.keras.Sequential([\n",
    "    Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "lenet5_features = lenet5.predict(image_array)\n",
    "\n",
    "# Combine handcrafted features with LeNet-5 features (ET)\n",
    "et_combined_features = np.concatenate((lenet5_features, handcrafted_features), axis=1)\n",
    "\n",
    "# Combine EEG and ET features\n",
    "combined_features = np.concatenate((combined_eeg_features, et_combined_features), axis=1)\n",
    "\n",
    "# Handle imbalanced data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "combined_features_resampled, labels_resampled = smote.fit_resample(combined_features, Label)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features_resampled, labels_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Best parameters found by Optuna (previously optimized)\n",
    "best_params = {'rf_n_estimators': 265, 'gb_n_estimators': 89, 'xgb_n_estimators': 300}\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=best_params['rf_n_estimators'])\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=best_params['gb_n_estimators'])\n",
    "xgb_clf = XGBClassifier(n_estimators=best_params['xgb_n_estimators'])\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[\n",
    "    ('rf', rf_clf), \n",
    "    ('gb', gb_clf),\n",
    "    ('xgb', xgb_clf)\n",
    "], final_estimator=RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "# Cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "y_test_proba = []\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    X_train_cv, X_val_cv = X_train[train_index], X_train[val_index]\n",
    "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    stacking_clf.fit(X_train_cv, y_train_cv)\n",
    "    y_val_pred = stacking_clf.predict(X_val_cv)\n",
    "    y_val_proba = stacking_clf.predict_proba(X_val_cv)[:, 1]\n",
    "    y_test_proba.append(stacking_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_val_cv, y_val_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "ax.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=.8)\n",
    "ax.set(xlim=[0, 1], ylim=[0, 1], title=\"Receiver Operating Characteristic\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Final evaluation\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
